{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "Subash Sunku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports are prefered to be all at the top\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn import linear_model \n",
    "from sklearn.decomposition import PCA\n",
    "import statistics \n",
    "import math \n",
    "from collections import OrderedDict \n",
    "import scipy.stats as scs\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. [30] (Smoothing) Write functions that use the cut() and qcut() functions provided by DataFrame to smooth data in a given column using the following methods. Apply these function on column F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a1</td>\n",
       "      <td>b1</td>\n",
       "      <td>964</td>\n",
       "      <td>-0.5886</td>\n",
       "      <td>9.755</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a1</td>\n",
       "      <td>b2</td>\n",
       "      <td>5342</td>\n",
       "      <td>-1.355</td>\n",
       "      <td>31.34</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>a1</td>\n",
       "      <td>b1</td>\n",
       "      <td>7265</td>\n",
       "      <td>-0.3449</td>\n",
       "      <td>0.6031</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>a2</td>\n",
       "      <td>b2</td>\n",
       "      <td>5787</td>\n",
       "      <td>-0.729</td>\n",
       "      <td>10.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>a1</td>\n",
       "      <td>b2</td>\n",
       "      <td>2889</td>\n",
       "      <td>1.196</td>\n",
       "      <td>21.86</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>a3</td>\n",
       "      <td>b1</td>\n",
       "      <td>462</td>\n",
       "      <td>-1.526</td>\n",
       "      <td>8.703</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>a2</td>\n",
       "      <td>b2</td>\n",
       "      <td>7285</td>\n",
       "      <td>-0.7289</td>\n",
       "      <td>8.265</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>a1</td>\n",
       "      <td>b2</td>\n",
       "      <td>8728</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>8.913</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>a2</td>\n",
       "      <td>b2</td>\n",
       "      <td>2143</td>\n",
       "      <td>0.4221</td>\n",
       "      <td>17.91</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>1301</td>\n",
       "      <td>-0.2679</td>\n",
       "      <td>9.662</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A   B     C       D      E  F\n",
       "0    a1  b1   964 -0.5886  9.755  6\n",
       "1    a1  b2  5342  -1.355  31.34  7\n",
       "2    a1  b1  7265 -0.3449 0.6031  3\n",
       "3    a2  b2  5787  -0.729  10.15  1\n",
       "4    a1  b2  2889   1.196  21.86  2\n",
       "..   ..  ..   ...     ...    ... ..\n",
       "995  a3  b1   462  -1.526  8.703  1\n",
       "996  a2  b2  7285 -0.7289  8.265  7\n",
       "997  a1  b2  8728  -0.612  8.913  5\n",
       "998  a2  b2  2143  0.4221  17.91  7\n",
       "999  a2  b1  1301 -0.2679  9.662  5\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:.04}' .format\n",
    "#Read CSV to Dataframe:\n",
    "df = pd.read_csv('hwk01.csv', index_col = 0)\n",
    "def eq_binnin(df, col_name, binning_method, replace_type, depth):\n",
    "    bins = int(len(df)/depth)\n",
    "    \n",
    "    if binning_method == 'equal_depth':\n",
    "        df['G'] = pd.qcut(df[col_name].rank(method='first'),bins)\n",
    "    elif binning_method == 'equal_width': \n",
    "        df['G'] = pd.cut(df[col_name],bins) \n",
    "        \n",
    "    sets = []\n",
    "    for i, j in enumerate(df.groupby('G')[col_name].groups.values()):\n",
    "        sets.append(df[col_name].iloc[j].index.values)\n",
    "    if replace_type == 'mean':\n",
    "        for i,j in enumerate(df.groupby('G')[col_name].mean()):\n",
    "            df.loc[sets[i],'F_mean'] = j\n",
    "        return df['F_mean'].round(4)\n",
    "    elif replace_type == 'boundary':\n",
    "        for i,j in enumerate(zip(df.groupby('G')[col_name].max(),df.groupby('G')[col_name].min())):\n",
    "            maxi = j[0]\n",
    "            mini = j[1]\n",
    "            for k in range(depth):\n",
    "                if (abs(df.loc[sets[i][k],col_name] - mini) >= abs(df.loc[sets[i][k],col_name] - maxi)):\n",
    "                    df.loc[sets[i][k],'F_boundary'] = maxi\n",
    "                else:\n",
    "                    df.loc[sets[i][k],'F_boundary'] = mini\n",
    "        return df['F_boundary'].round(4)\n",
    "    else:\n",
    "        print(\"Replace method provided is not available, using default median:\")\n",
    "        for i,j in enumerate(df.groupby('G')[col_name].median()):\n",
    "            df.loc[sets[i],'F_median'] = j\n",
    "        return df['F_median'].round(4)\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a Equal-depth binning with bin means for depth k, for example k = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column F after applying Equal-depth binning with bin means for depth 100: \n",
      "0     5.42\n",
      "1     6.32\n",
      "2     2.25\n",
      "3     1.06\n",
      "4     1.06\n",
      "      ... \n",
      "995   1.06\n",
      "996   7.43\n",
      "997   5.42\n",
      "998   7.43\n",
      "999   5.42\n",
      "Name: F_mean, Length: 1000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def eq_depth_mean(df,depth):\n",
    "    bins = int(len(df)/depth)\n",
    "    df['G'] = pd.qcut(df['F'].rank(method='first'),bins)\n",
    "    sets = []\n",
    "    for i, j in enumerate(df.groupby('G')['F'].groups.values()):\n",
    "        sets.append(df['F'].iloc[j].index.values)\n",
    "\n",
    "    for i,j in enumerate(df.groupby('G')['F'].mean()):\n",
    "        df.loc[sets[i],'F_mean'] = j\n",
    "    return df['F_mean'].round(4)\n",
    "\n",
    "print('Column F after applying Equal-depth binning with bin means for depth 100: ')\n",
    "#print(eq_depth_mean(df,100))\n",
    "#You can use seperate function to display or using the common function\n",
    "print(eq_binnin(df, 'F', 'equal_depth', 'mean', 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b  Equal-depth binning with bin boundaries for depth k, for example k = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column F after applying Equal-depth binning with bin boundaries for depth 100: \n",
      "0     6.0\n",
      "1     7.0\n",
      "2     3.0\n",
      "3     1.0\n",
      "4     2.0\n",
      "       ..\n",
      "995   1.0\n",
      "996   7.0\n",
      "997   5.0\n",
      "998   7.0\n",
      "999   5.0\n",
      "Name: F_boundary, Length: 1000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def eq_depth_boundaries(df,depth):\n",
    "    sets = []\n",
    "    for i, j in enumerate(df.groupby('G')['F'].groups.values()):\n",
    "        sets.append(df['F'].iloc[j].index.values)\n",
    "\n",
    "    for i,j in enumerate(zip(df.groupby('G')['F'].max(),df.groupby('G')['F'].min())):\n",
    "        maxi = j[0]\n",
    "        mini = j[1]\n",
    "        for k in range(100):\n",
    "            if (abs(df.loc[sets[i][k],'F'] - mini) >= abs(df.loc[sets[i][k],'F'] - maxi)):\n",
    "                df.loc[sets[i][k],'F_bound'] = maxi\n",
    "            else:\n",
    "                df.loc[sets[i][k],'F_bound'] = mini\n",
    "        #print(j[0],j[1])\n",
    "    return df['F_bound'].round(4)\n",
    "print('Column F after applying Equal-depth binning with bin boundaries for depth 100: ')\n",
    "#print(eq_depth_boundaries(df,100))\n",
    "print(eq_binnin(df, 'F', 'equal_depth', 'boundary', 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c Equal-width binning with bin median for 10 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column F after applying Equal-width binning with bin median for 10 bins: \n",
      "Replace method provided is not available, using default median:\n",
      "0     6.0\n",
      "1     7.0\n",
      "2     3.0\n",
      "3     1.0\n",
      "4     1.0\n",
      "       ..\n",
      "995   1.0\n",
      "996   7.0\n",
      "997   5.0\n",
      "998   7.0\n",
      "999   5.0\n",
      "Name: F_median, Length: 1000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def eq_depth_median(df,bins):\n",
    "    df['H'] = pd.cut(df['F'],bins)\n",
    "    sets = []\n",
    "    for i, j in enumerate(df.groupby('H')['F'].groups.values()):\n",
    "        sets.append(df['F'].iloc[j].index.values)\n",
    "\n",
    "    for i,j in enumerate(df.groupby('H')['F'].median()):\n",
    "        df.loc[sets[i],'F_median'] = j\n",
    "    return df['F_median'].round(4)\n",
    "print('Column F after applying Equal-width binning with bin median for 10 bins: ')\n",
    "#print(eq_depth_median(df,10))\n",
    "print(eq_binnin(df, 'F', 'equal_width', 'median', 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. [30] (Data Reduction) Write a function that takes a DataFrame, a set of column names (of numeric columns), and an integer p (less than the total number of columns in the table), and use PCA method in Scikit-Learn (specifically, sklearn.decomposition.PCA) to reduce the set of columns into p new columns. Apply this function to reduce the columns {C, D, E, F} into two columns p1, and p2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.221e+03</td>\n",
       "      <td>-5.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-157.3</td>\n",
       "      <td>15.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-2.08e+03</td>\n",
       "      <td>-14.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-602.3</td>\n",
       "      <td>-5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.296e+03</td>\n",
       "      <td>6.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>4.723e+03</td>\n",
       "      <td>-6.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>-2.1e+03</td>\n",
       "      <td>-7.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>-3.543e+03</td>\n",
       "      <td>-6.354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>3.042e+03</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>3.884e+03</td>\n",
       "      <td>-5.992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            p1     p2\n",
       "0    4.221e+03 -5.917\n",
       "1       -157.3  15.89\n",
       "2    -2.08e+03 -14.74\n",
       "3       -602.3  -5.26\n",
       "4    2.296e+03  6.283\n",
       "..         ...    ...\n",
       "995  4.723e+03 -6.977\n",
       "996   -2.1e+03 -7.082\n",
       "997 -3.543e+03 -6.354\n",
       "998  3.042e+03   2.29\n",
       "999  3.884e+03 -5.992\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:.04}' .format\n",
    "def data_reduction(df,columns,p):\n",
    "    if p > len(columns):\n",
    "        raise ValueError('p value should be less than columns')\n",
    "    x = df.loc[:, columns].values\n",
    "    pca = PCA(n_components=p)\n",
    "    principalComponents = pca.fit_transform(x)\n",
    "    return pd.DataFrame(data = principalComponents, columns = ['p1', 'p2'])\n",
    "data_reduction(df,('C','D','E','F'),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. [40] (Correlation) For this question, you will need to use packages scipy.stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.a Compute the covariance and the correlation coefficient for each pair of the numeric columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance is: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>C</td>\n",
       "      <td>8.146e+06</td>\n",
       "      <td>50.39</td>\n",
       "      <td>-421.3</td>\n",
       "      <td>99.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D</td>\n",
       "      <td>50.39</td>\n",
       "      <td>1.003</td>\n",
       "      <td>-0.6001</td>\n",
       "      <td>0.0524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>E</td>\n",
       "      <td>-421.3</td>\n",
       "      <td>-0.6001</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-0.2313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F</td>\n",
       "      <td>99.65</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>-0.2313</td>\n",
       "      <td>9.747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          C       D       E       F\n",
       "C 8.146e+06   50.39  -421.3   99.65\n",
       "D     50.39   1.003 -0.6001  0.0524\n",
       "E    -421.3 -0.6001   101.0 -0.2313\n",
       "F     99.65  0.0524 -0.2313   9.747"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def covariance(df):\n",
    "    return df[['C','D','E','F']].cov().round(4)\n",
    "print(\"Covariance is: \")\n",
    "covariance(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation is: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>-0.0147</td>\n",
       "      <td>0.0112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0596</td>\n",
       "      <td>0.0167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>E</td>\n",
       "      <td>-0.0147</td>\n",
       "      <td>-0.0596</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>-0.0074</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C       D       E       F\n",
       "C     1.0  0.0176 -0.0147  0.0112\n",
       "D  0.0176     1.0 -0.0596  0.0167\n",
       "E -0.0147 -0.0596     1.0 -0.0074\n",
       "F  0.0112  0.0167 -0.0074     1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def correlation(df):\n",
    "    return df[['C','D','E','F']].corr().round(4)\n",
    "print(\"Correlation is: \")\n",
    "correlation(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.b Use the crosstab() function to construct the contingency table for columns A and B, similar to the following sample, where the distinct values in attribute A are {a1, a2} and in attribute B are {b1, b2, b3} (this is just a sample and may not be the same as  the data in your data file). Write a sequence of Python code to perform the Pearson’s chi-square (χ 2 ) test of independence with a confidence level of 0.001 to determine if the two attributes are correlated. You should use stats.chi2() to get the χ 2 distribution. Print sufficient information to report the result of the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Degree of Freedom is: 2\n",
      "\n",
      "P-value of the test: 0.001192572517069232\n",
      "\n",
      "The expected frequencies, based on the marginal sums of the table:\n",
      " [[180.846 189.711 220.443]\n",
      " [125.154 131.289 152.557]]\n",
      "\n",
      "chi2 value is: 13.4633 \n",
      "\n",
      "chi2 with alpha 0.001 is: 13.8155\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>A</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>b1</td>\n",
       "      <td>174</td>\n",
       "      <td>170</td>\n",
       "      <td>247</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>b2</td>\n",
       "      <td>132</td>\n",
       "      <td>151</td>\n",
       "      <td>126</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>All</td>\n",
       "      <td>306</td>\n",
       "      <td>321</td>\n",
       "      <td>373</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "A     a1   a2   a3   All\n",
       "B                       \n",
       "b1   174  170  247   591\n",
       "b2   132  151  126   409\n",
       "All  306  321  373  1000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://codingdisciple.com/chi-squared-python.html\n",
    "crosstab = pd.crosstab(df['B'],df['A'])\n",
    "crosstab_all = pd.crosstab(df['B'],df['A'],margins = True)\n",
    "#print(crosstab_all.iloc[0][0:3].values)\n",
    "#print(crosstab_all.iloc[1][0:3].values)\n",
    "chi2, p, dof, expected = scs.chi2_contingency(crosstab)\n",
    "#print(chi2, p, dof, expected)\n",
    "print(\"\\nDegree of Freedom is: \" + str(dof))\n",
    "print(\"\\nP-value of the test: \" + str(p))\n",
    "print(\"\\nThe expected frequencies, based on the marginal sums of the table:\\n \" + str(expected))\n",
    "alpha = 0.001\n",
    "chi2_alpha = scs.chi2.ppf(1-alpha,dof)\n",
    "print(\"\\nchi2 value is: \" + str(chi2.round(4)) + \" \\n\\nchi2 with alpha 0.001 is: \" + str(chi2_alpha.round(4)))\n",
    "print(\"\")\n",
    "crosstab_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
